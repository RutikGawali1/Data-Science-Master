{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Naive Bayes Classification - Theory and Assignment\n", "This notebook covers key questions on Naive Bayes classifiers and an assignment using the Spambase dataset."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q1: Probability of a smoker given they use the health insurance plan\n", "We are given:\n", "- Probability of using health insurance, \\( P(H) = 0.7 \\)\n", "- Probability of being a smoker given health insurance, \\( P(S | H) = 0.4 \\)\n", "Using Bayes' theorem:\n", "\\[\n", "P(S | H) = \\frac{P(H | S) P(S)}{P(H)}\n", "\\]\n", "Since we are given \\( P(S | H) \\), the answer is simply:\n", "\\[\n", "P(S | H) = 0.4 (or 40%)\n", "\\]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q2: Difference between Bernoulli Naive Bayes and Multinomial Naive Bayes\n", "- **Bernoulli Naive Bayes** is used for binary feature data (0 or 1). Example: Presence or absence of words in text.\n", "- **Multinomial Naive Bayes** is used for count-based data, like word frequency in text classification."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q3: Handling Missing Values in Bernoulli Naive Bayes\n", "Bernoulli Naive Bayes does not handle missing values directly. Some common approaches:\n", "- Impute missing values with 0 (assuming absence of feature).\n", "- Use median/mode of the data to fill missing values."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q4: Can Gaussian Naive Bayes be used for multi-class classification?\n", "Yes, Gaussian Naive Bayes can handle multi-class classification by applying Bayes' theorem separately for each class and choosing the class with the highest probability."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q5: Assignment - Spam Classification using Naive Bayes\n", "### Steps:\n", "1. Load the Spambase dataset.\n", "2. Preprocess the data.\n", "3. Implement Bernoulli, Multinomial, and Gaussian Naive Bayes classifiers.\n", "4. Perform 10-fold cross-validation.\n", "5. Evaluate and compare performance metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n", "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "# Load Spambase dataset (Download manually from UCI repository)\n", "data = pd.read_csv('spambase.data', header=None)\n", "\n", "# Split features and labels\n", "X = data.iloc[:, :-1]\n", "y = data.iloc[:, -1]\n", "\n", "# Standardize data for Gaussian Naive Bayes\n", "scaler = StandardScaler()\n", "X_scaled = scaler.fit_transform(X)\n", "\n", "# Initialize classifiers\n", "bnb = BernoulliNB()\n", "mnb = MultinomialNB()\n", "gnb = GaussianNB()\n", "\n", "# Perform 10-fold cross-validation and compute metrics\n", "classifiers = {'BernoulliNB': bnb, 'MultinomialNB': mnb, 'GaussianNB': gnb}\n", "metrics = {}\n", "\n", "for name, clf in classifiers.items():\n", "    if name == 'GaussianNB':\n", "        X_data = X_scaled\n", "    else:\n", "        X_data = X\n", "    \n", "    accuracy = np.mean(cross_val_score(clf, X_data, y, cv=10, scoring='accuracy'))\n", "    precision = np.mean(cross_val_score(clf, X_data, y, cv=10, scoring='precision'))\n", "    recall = np.mean(cross_val_score(clf, X_data, y, cv=10, scoring='recall'))\n", "    f1 = np.mean(cross_val_score(clf, X_data, y, cv=10, scoring='f1'))\n", "    \n", "    metrics[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}\n", "\n", "# Display results\n", "for model, scores in metrics.items():\n", "    print(f\"{model} Performance:\")\n", "    for metric, value in scores.items():\n", "        print(f\"{metric}: {value:.4f}\")\n", "    print(\"\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Discussion and Conclusion\n", "- The classifier that performs best depends on the dataset.\n", "- Multinomial Naive Bayes usually works well with text data (word counts).\n", "- Bernoulli Naive Bayes is better for binary feature data.\n", "- Gaussian Naive Bayes can handle continuous features.\n", "### Limitations of Naive Bayes:\n", "- Assumes feature independence, which is often unrealistic.\n", "- Performs poorly with correlated features.\n", "- Sensitive to data imbalance.\n", "\n", "**Future Work:**\n", "- Experiment with feature engineering.\n", "- Try alternative models like Logistic Regression or Random Forest."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 4}